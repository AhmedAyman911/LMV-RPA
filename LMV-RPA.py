# -*- coding: utf-8 -*-
"""LMV-RPA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QC3tqokuQIEX8kIHQ3l4YzgmeQU6zxlz

OCRed LLM
"""

# Step 1: Install necessary libraries
!pip uninstall -y tensorflow  # Uninstall TensorFlow to avoid conflicts with PyTorch
!pip install paddlepaddle paddleocr
!pip install pytesseract
!pip install python-doctr[torch,viz]
!apt install tesseract-ocr
!sudo apt-get install fonts-freefont-ttf -y  # Optional for result visualization with Doctr

!pip install easyocr
# Import EasyOCR
import easyocr

# Step 2: Import necessary modules
import paddleocr
from paddleocr import PaddleOCR
import pytesseract
from PIL import Image
from doctr.io import DocumentFile
from doctr.models import ocr_predictor
from google.colab import files
import cv2
import matplotlib.pyplot as plt

# Step 3: Define OCR functions for each model
# PaddleOCR function
def paddle_ocr(image_path):
    ocr = PaddleOCR(use_angle_cls=True, lang='en')  # English language model
    result = ocr.ocr(image_path)
    extracted_text = ''
    for line in result:
        extracted_text += ' '.join([word_info[1][0] for word_info in line]) + '\n'
    return extracted_text

# TesseractOCR function
def tesseract_ocr(image_path):
    img = Image.open(image_path)
    text = pytesseract.image_to_string(img)
    return text

# DoctrOCR function
def doctr_ocr(image_path):
    # Instantiate a pretrained Doctr OCR model (with PyTorch backend)
    predictor = ocr_predictor(pretrained=True)
    # Load the image for Doctr
    doc = DocumentFile.from_images(image_path)
    result = predictor(doc)

    # Export plain text from Doctr OCR
    string_result = result.render()
    return string_result

# EasyOCR function
def easy_ocr_func(image_path):
    reader = easyocr.Reader(['en'], gpu=False)  # Initialize EasyOCR reader (use GPU=True if GPU is available)
    result = reader.readtext(image_path)

    # Extract text from result
    extracted_text = ''
    for detection in result:
        extracted_text += detection[1] + '\n'  # The text is in the second position of the tuple
    return extracted_text

def extract_text_from_ocr(image_path):
    """
    This function extracts text from an image using multiple OCR models:
    - PaddleOCR
    - TesseractOCR
    - DoctrOCR
    - EasyOCR

    Parameters:
    image_path (str): The path to the image file.

    Returns:
    dict: A dictionary with text extracted from each OCR model.
    """

    # Extract text using PaddleOCR
    paddle_text = paddle_ocr(image_path)

    # Extract text using TesseractOCR
    tesseract_text = tesseract_ocr(image_path)

    # Extract text using DoctrOCR
    doctr_text = doctr_ocr(image_path)

    # Extract text using EasyOCR
    easyocr_text = easy_ocr_func(image_path)

    # Return results as a dictionary
    return {
        'PaddleOCR': paddle_text,
        'TesseractOCR': tesseract_text,
        'DoctrOCR': doctr_text,
        'EasyOCR': easyocr_text
    }

"""

---

# LLM

---

"""

# install dependencies
!pip install diffusers
!pip install transformers

!pip install transformers accelerate bitsandbytes

!pip install -U bitsandbytes

!pip install -U transformers accelerate bitsandbytes

from google.colab import userdata
import google.generativeai as genai

genai.configure(api_key=userdata.get("74916961943"))

from google.colab import userdata
userdata.get('74916961943')

instruction = (
    """
    You are given extracted text from an invoice, extract the data and return them in the following order:
    invoice object with client name, invoice number, invoice date, due date.
    Item purchased objects with their description, quantity , and total price.
    quantity can be also QTY.
    subtotal object with tax(if applicable), discount(if applicable), and total.
    Payment instructions with due date, bank name, account number, and payment method.
    in JSON format for direct use without any extra text.
    additionally, dont write json before the text
    """
)

model = genai.GenerativeModel(
    "models/gemini-1.5-pro", system_instruction=instruction
)

def generate_gemini_content(paddle_text, tesseract_text, doctr_text, easyocr_text, model):

    # Generate content using the provided model
    paddle_gemini = model.generate_content(f'{paddle_text}')
    tesseract_gemini = model.generate_content(f'{tesseract_text}')
    doctr_gemini = model.generate_content(f'{doctr_text}')
    easyocr_gemini = model.generate_content(f'{easyocr_text}')

    # Return the generated content as a dictionary
    return {
        'PaddleGemini': paddle_gemini.text,
        'TesseractGemini': tesseract_gemini.text,
        'DoctrGemini': doctr_gemini.text,
        'EasyOCRGemini': easyocr_gemini.text
    }

def generate_llama_content(paddle_text, tesseract_text, doctr_text, easyocr_text):

    # Generate content using the provided model
    easyocr_llama = llama_model(easyocr_text)
    paddle_llama = llama_model(paddle_text)
    tesseract_llama = llama_model(tesseract_text)
    doctr_llama = llama_model(doctr_text)

    # Return the generated content as a dictionary
    return {
        'PaddleLlama': paddle_llama,
        'TesseractLlama': tesseract_llama,
        'DoctrLlama': doctr_llama,
        'EasyOCRLlama': easyocr_llama
    }

def generate_Majority_content(easyocr_llama, paddle_llama, tesseract_llama, doctr_llama, gemini_results):
    Majority = model.generate_content(
        f"First: {easyocr_llama}\n"
        f"Second: {paddle_llama}\n"
        f"Third: {tesseract_llama}\n"
        f"Fourth: {doctr_llama}\n"
        f"Fifth: {gemini_results['PaddleGemini']}\n"
        f"Sixth: {gemini_results['TesseractGemini']}\n"
        f"Seventh: {gemini_results['DoctrGemini']}\n"
        f"Eighth: {gemini_results['EasyOCRGemini']}\n"
    )
    return Majority.text

!pip install groq

import os
#os.environ['GROQ_API_KEY'] = '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'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
os.environ['GROQ_API_KEY'] = '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'
# Check if the environment variable is set (optional)
print(os.getenv('GROQ_API_KEY'))

from groq import Groq
client = Groq(
    api_key=os.environ.get("GROQ_API_KEY"),
)
def llama_model(ocr_text):
    completion = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {
                "role": "system",
                "content": "You are given extracted text from an invoice, extract the data and return them in the following order:\n    invoice object with client name, invoice number, invoice date, due date.\n    Item purchased objects with their description, quantity, and total price.\n    quantity can be also QTY.\n    subtotal object with tax(if applicable), discount(if applicable), and total.\n    Payment instructions with due date, bank name, account number, and payment method.\n    in JSON format for direct use without any extra text.\n    additionally, dont write json before the text"
            },
            {
                "role": "user",
                "content": f'{ocr_text}'
            }
        ],
        temperature=1,
        max_tokens=8192,
        top_p=1,
        stream=True,
        stop=None,
    )

    # Collect the response for the current OCR text
    response = ""
    for chunk in completion:
        response += chunk.choices[0].delta.content or ""

    return response

"""### `**Majority**`"""

from google.colab import userdata
import google.generativeai as genai

genai.configure(api_key=userdata.get("majority_Api"))
from google.colab import userdata
userdata.get('majority_Api')

instructionM = (
    """
You will receive multiple JSON-formatted inputs, and your task is to compare the values across all inputs and return a single merged JSON object. For keys that are identical across inputs, compare the values: if the values are identical, include the key-value pair in the final output; if values differ for the same key, include only the most frequently occurring value. In cases of a tie where two or more values have the same frequency, you may include one of the tied values. If a key appears in only one input, add that key-value pair to the final output. Ensure that no data is discarded unnecessarily and return the result in valid JSON format.
"""
)

model = genai.GenerativeModel(
    "models/gemini-1.5-pro", system_instruction=instructionM
)

# Step 4: Upload Image
# uploaded = files.upload()
#image_path = '/content/rr.png'
import os
import time
import csv

# Define the folder path where images will be added
folder_path = '/content/images/'

# Create the folder if it doesn't exist
os.makedirs(folder_path, exist_ok=True)

# Function to get the current set of images in the folder
def get_image_files():
    return {f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))}

# Initial set of images
processed_images = get_image_files()

# Function to save the results to CSV
def save_results_to_csv(data, csv_filename='results.csv'):
    # Create/append to CSV file
    with open(csv_filename, mode='a', newline='') as file:
        writer = csv.writer(file)
        # Writing the header only if the file is empty
        if file.tell() == 0:
            writer.writerow(["Image", "PaddleOCR", "TesseractOCR", "DoctrOCR", "EasyOCR",
                             "PaddleLlama", "TesseractLlama", "DoctrLlama", "EasyOCRLlama",
                             "PaddleGemini", "TesseractGemini", "DoctrGemini", "EasyOCRGemini",
                             "MajorityContent", "TimeEnded", "TimeTaken(seconds)"])
        # Write the data row
        writer.writerow(data)

# Function to process the image
def process_image(image_path):
    start_time = time.time()  # Track the start time

    # OCR extraction
    print(f"Processing image: {image_path} - OCR stage")
    ocr_results = extract_text_from_ocr(image_path)

    # Llama and Gemini processing
    print(f"Processing image: {image_path} - LLM (Gemini) stage")
    gemini_results = generate_gemini_content(
        ocr_results['PaddleOCR'],
        ocr_results['TesseractOCR'],
        ocr_results['DoctrOCR'],
        ocr_results['EasyOCR'],
        model
    )
    print(f"Processing image: {image_path} - LLM (Llama) stage")
    llama_results = generate_llama_content(
        ocr_results['PaddleOCR'],
        ocr_results['TesseractOCR'],
        ocr_results['DoctrOCR'],
        ocr_results['EasyOCR'],
    )

    # Majority content generation
    print(f"Processing image: {image_path} - Majority content stage")
    majority_content = generate_Majority_content(
        llama_results['EasyOCRLlama'],
        llama_results['PaddleLlama'],
        llama_results['TesseractLlama'],
        llama_results['DoctrLlama'],
        gemini_results
    )

    end_time = time.time()  # Track the end time
    time_taken = end_time - start_time  # Calculate how much time the process took

    # Save all results to CSV
    print(f"Processing image: {image_path} - Saving results to CSV")
    save_results_to_csv([
        image_path,
        ocr_results['PaddleOCR'], ocr_results['TesseractOCR'], ocr_results['DoctrOCR'], ocr_results['EasyOCR'],
        llama_results['PaddleLlama'], llama_results['TesseractLlama'], llama_results['DoctrLlama'], llama_results['EasyOCRLlama'],
        gemini_results['PaddleGemini'], gemini_results['TesseractGemini'], gemini_results['DoctrGemini'], gemini_results['EasyOCRGemini'],
        majority_content,
        time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time)),  # End time in human-readable format
        round(time_taken, 2)  # Time taken in seconds (rounded)
    ])

# Infinite loop to continuously check for new images
try:
    while True:
        # Get the updated set of images
        current_images = get_image_files()

        # Find new images by comparing with the processed images set
        new_images = current_images - processed_images

        if new_images:
            for new_image in new_images:
                image_path = os.path.join(folder_path, new_image)
                process_image(image_path)

            # Update the processed images set
            processed_images = current_images

        # Sleep for a short interval before checking again
        time.sleep(5)  # Check every 5 seconds

except KeyboardInterrupt:
    print("Stopped watching the folder.")